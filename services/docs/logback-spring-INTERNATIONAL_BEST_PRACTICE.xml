<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- 引入Spring Boot默认配置 -->
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <!-- 定义属性 -->
    <property name="LOG_DIR" value="logs"/>
    <property name="SERVICE_NAME" value="chat-service"/>
    <property name="LOG_FILE_MAX_SIZE" value="100MB"/>
    <property name="LOG_FILE_MAX_HISTORY" value="30"/>
    <property name="LOG_FILE_TOTAL_SIZE" value="3GB"/>
    
    <!-- 获取环境变量 -->
    <springProperty name="SERVICE_VERSION" source="application.version" defaultValue="1.0.0"/>
    <springProperty name="ENVIRONMENT" source="spring.profiles.active" defaultValue="local"/>
    <springProperty name="LOGSTASH_HOST" source="logstash.host" defaultValue="localhost"/>
    <springProperty name="LOGSTASH_PORT" source="logstash.port" defaultValue="5000"/>
    
    <!-- ============================================ -->
    <!-- 1. 标准日志格式Appender（控制台）-->
    <!-- ============================================ -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>
                %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    
    <!-- ============================================ -->
    <!-- 2. ECS标准JSON格式Appender（本地文件）-->
    <!-- ============================================ -->
    <appender name="FILE_JSON" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_DIR}/${SERVICE_NAME}.log</file>
        <append>true</append>
        
        <!-- ECS标准JSON编码器 -->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <!-- 自定义字段 - 服务信息（ECS兼容） -->
            <customFields>
                {
                    "service.name": "${SERVICE_NAME}",
                    "service.version": "${SERVICE_VERSION}",
                    "service.environment": "${ENVIRONMENT}",
                    "host.hostname": "${HOSTNAME:unknown}",
                    "log.schema_version": "1.0"
                }
            </customFields>
            
            <!-- 包含MDC信息（用于追踪链路） -->
            <includeContext>true</includeContext>
            
            <!-- 包含日志级别 -->
            <includeLevelName>true</includeLevelName>
            
            <!-- 包含线程名 -->
            <includeThreadName>true</includeThreadName>
            
            <!-- 异常堆栈追踪 -->
            <includeException>true</includeException>
            
            <!-- 自定义日志转换器（用于PII脱敏） -->
            <jsonGeneratorDecorator>
                <class>com.example.logging.SensitiveDataJsonDecorator</class>
            </jsonGeneratorDecorator>
        </encoder>
        
        <!-- 日志轮转策略（按大小和时间） -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>
                ${LOG_DIR}/archive/${SERVICE_NAME}-%d{yyyy-MM-dd}.%i.log
            </fileNamePattern>
            <maxFileSize>${LOG_FILE_MAX_SIZE}</maxFileSize>
            <maxHistory>${LOG_FILE_MAX_HISTORY}</maxHistory>
            <totalSizeCap>${LOG_FILE_TOTAL_SIZE}</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- ============================================ -->
    <!-- 3. 分离ERROR日志（重要日志分存储） -->
    <!-- ============================================ -->
    <appender name="FILE_ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_DIR}/${SERVICE_NAME}-ERROR.log</file>
        <append>true</append>
        
        <!-- 只记录ERROR级别 -->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
        </filter>
        
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>
                {
                    "service.name": "${SERVICE_NAME}",
                    "log.level": "ERROR",
                    "log.classification": "CRITICAL"
                }
            </customFields>
            <includeContext>true</includeContext>
            <includeLevelName>true</includeLevelName>
        </encoder>
        
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>
                ${LOG_DIR}/archive/ERROR/${SERVICE_NAME}-ERROR-%d{yyyy-MM-dd}.%i.log
            </fileNamePattern>
            <maxFileSize>${LOG_FILE_MAX_SIZE}</maxFileSize>
            <maxHistory>90</maxHistory>
            <totalSizeCap>${LOG_FILE_TOTAL_SIZE}</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- ============================================ -->
    <!-- 4. 敏感数据分离存储 -->
    <!-- ============================================ -->
    <appender name="FILE_SENSITIVE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_DIR}/${SERVICE_NAME}-SENSITIVE.log</file>
        <append>true</append>
        
        <!-- 仅记录包含敏感信息的日志 -->
        <filter class="com.example.logging.SensitiveDataFilter"/>
        
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>
                {
                    "service.name": "${SERVICE_NAME}",
                    "log.classification": "SENSITIVE",
                    "compliance.requires_encryption": true
                }
            </customFields>
            <includeContext>true</includeContext>
        </encoder>
        
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>
                ${LOG_DIR}/archive/SENSITIVE/${SERVICE_NAME}-SENSITIVE-%d{yyyy-MM-dd}.%i.log
            </fileNamePattern>
            <maxFileSize>50MB</maxFileSize>
            <maxHistory>365</maxHistory>  <!-- 保留1年用于审计 -->
        </rollingPolicy>
    </appender>
    
    <!-- ============================================ -->
    <!-- 5. Logstash TCP Appender（生产数据导出） -->
    <!-- ============================================ -->
    <appender name="LOGSTASH_TCP" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>${LOGSTASH_HOST}:${LOGSTASH_PORT}</destination>
        
        <!-- TCP连接超时 -->
        <connectionTimeout>5000</connectionTimeout>
        
        <!-- 异常处理策略 -->
        <includeCallerData>false</includeCallerData>
        
        <!-- 编码器配置 -->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>
                {
                    "service.name": "${SERVICE_NAME}",
                    "service.version": "${SERVICE_VERSION}",
                    "deployment.environment": "${ENVIRONMENT}",
                    "@index_name": "logs-${SERVICE_NAME}-${ENVIRONMENT}-${HOSTNAME:unknown}"
                }
            </customFields>
            <includeContext>true</includeContext>
            <includeLevelName>true</includeLevelName>
            <includeThreadName>true</includeThreadName>
        </encoder>
        
        <!-- 自动重连机制 -->
        <reconnectionDelay>5000</reconnectionDelay>
    </appender>
    
    <!-- ============================================ -->
    <!-- 6. 异步Appender（性能优化） -->
    <!-- ============================================ -->
    
    <!-- 异步JSON文件输出 -->
    <appender name="ASYNC_FILE_JSON" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>512</queueSize>           <!-- 缓冲队列大小 -->
        <discardingThreshold>0</discardingThreshold>  <!-- 不丢弃任何日志 -->
        <appender-ref ref="FILE_JSON"/>
    </appender>
    
    <!-- 异步错误日志 -->
    <appender name="ASYNC_FILE_ERROR" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>256</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <appender-ref ref="FILE_ERROR"/>
    </appender>
    
    <!-- 异步Logstash输出 -->
    <appender name="ASYNC_LOGSTASH" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>1024</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <appender-ref ref="LOGSTASH_TCP"/>
    </appender>
    
    <!-- ============================================ -->
    <!-- 7. 日志级别规范配置 -->
    <!-- ============================================ -->
    
    <!-- 本地/开发环境 -->
    <springProfile name="local,dev">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE_JSON"/>
        </root>
        
        <!-- 应用包调试级别 -->
        <logger name="com.example" level="DEBUG" additivity="false">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE_JSON"/>
        </logger>
        
        <!-- Spring框架日志级别 -->
        <logger name="org.springframework" level="WARN"/>
        <logger name="org.hibernate" level="WARN"/>
        <logger name="org.springframework.web" level="INFO"/>
    </springProfile>
    
    <!-- Docker环境 -->
    <springProfile name="docker">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
        </root>
        
        <!-- 关键业务模块 -->
        <logger name="com.example.auth" level="INFO" additivity="false">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
            <appender-ref ref="ASYNC_FILE_SENSITIVE"/>
        </logger>
        
        <logger name="com.example.payment" level="INFO" additivity="false">
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>  <!-- 支付日志必须发送到中央系统 -->
            <appender-ref ref="ASYNC_FILE_ERROR"/>
        </logger>
    </springProfile>
    
    <!-- 生产环境 -->
    <springProfile name="prod,production">
        <!-- 根日志级别 -->
        <root level="INFO">
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
            <appender-ref ref="ASYNC_FILE_ERROR"/>
        </root>
        
        <!-- 关键业务模块持久化 -->
        <logger name="com.example.auth" level="INFO" additivity="false">
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
            <appender-ref ref="ASYNC_FILE_SENSITIVE"/>
        </logger>
        
        <logger name="com.example.payment" level="INFO" additivity="false">
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
            <appender-ref ref="ASYNC_FILE_SENSITIVE"/>
            <appender-ref ref="ASYNC_FILE_ERROR"/>
        </logger>
        
        <logger name="com.example.order" level="INFO" additivity="false">
            <appender-ref ref="ASYNC_FILE_JSON"/>
            <appender-ref ref="ASYNC_LOGSTASH"/>
        </logger>
        
        <!-- 第三方库日志限制 -->
        <logger name="org.springframework" level="WARN"/>
        <logger name="org.hibernate" level="WARN"/>
        <logger name="org.apache.http" level="WARN"/>
        <logger name="com.zaxxer.hikari" level="WARN"/>
        <logger name="org.apache.kafka" level="WARN"/>
    </springProfile>
    
    <!-- ============================================ -->
    <!-- 8. 动态日志级别调整（运行时修改） -->
    <!-- ============================================ -->
    <jmxConfigurator/>
    
</configuration>
